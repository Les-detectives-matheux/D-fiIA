{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation paramètres de la SVM One Class\n",
    "\n",
    "Pour un noyau Gaussien, la matrice de gram sera de la forme :\n",
    "\n",
    "K(xi, xj) = exp ( - gamma * d(xi, xj)^2  )\n",
    "\n",
    "Trois remarques :\n",
    "1. quelle que soit la valeur de nu, la matrice de Gram ne changera pas\n",
    "2. vous pourriez partir d'une matrice de distances d(xi, xj)^2 et dériver les matrices de Gram pour chaque gamma assez rapidement\n",
    "3. il est possible de fournir à scikit-learn une matrice de Gram pré-calculée en utilisant le noyau \"precomputed\" (regardez des exemples pour comprendre comment construire les matrices d'apprentissage et de test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interprétation du nu:\n",
    "\n",
    "A low C makes the decision surface smooth, while a high C aims at classifying all training examples correctly.\n",
    "\n",
    "Interprétation de gamma:\n",
    "\n",
    "gamma defines how much influence a single training example has. \n",
    "The larger gamma is, the closer other examples must be to be affected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom kernel\n",
    "\n",
    "You can define your own kernels by either giving the kernel as a python function or by precomputing the Gram matrix.\n",
    "\n",
    "Classifiers with custom kernels behave the same way as any other classifiers, except that:\n",
    "\n",
    "    Field support_vectors_ is now empty, only indices of support vectors are stored in support_\n",
    "    A reference (and not a copy) of the first argument in the fit() method is stored for future reference. If that array changes between the use of fit() and predict() you will have unexpected results.\n",
    "    \n",
    "### Use the Gram matrix\n",
    "\n",
    "Set kernel='precomputed' and pass the Gram matrix instead of X in the fit method. At the moment, the kernel values between all training vectors and the test vectors must be provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import numpy as np\n",
    ">>> from sklearn import svm\n",
    ">>> X = np.array([[0, 0], [1, 1]])\n",
    ">>> y = [0, 1]\n",
    ">>> clf = svm.SVC(kernel='precomputed')\n",
    ">>> # linear kernel computation\n",
    ">>> gram = np.dot(X, X.T)\n",
    ">>> clf.fit(gram, y) \n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='precomputed', max_iter=-1, probability=False,\n",
    "    random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    ">>> # predict on training examples\n",
    ">>> clf.predict(gram)\n",
    "array([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sur notre jeu de données\n",
    "\n",
    "Dans notre cas, on veut utiliser le noyau gaussien donc la matrice Gram est : \n",
    "    K(xi, xj) = exp ( - gamma * d(xi, xj)^2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_hdf('train.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid = pd.read_hdf('validation.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 116, -1: 478})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "value_gamma=0.001\n",
    "SVM_oneclass_kernelPrecomputed = svm.OneClassSVM(kernel='precomputed', gamma=value_gamma)\n",
    "# rbf kernel computation\n",
    "gram = np.exp(-value_gamma*cdist(data_train, data_train, 'euclidean')**2)\n",
    "SVM_oneclass_kernelPrecomputed.fit(gram) \n",
    "\n",
    "# predict on training examples\n",
    "gram_valid = np.exp(-value_gamma*cdist(data_valid, data_train, 'euclidean')**2)\n",
    "pred_anomaly = SVM_oneclass_kernelPrecomputed.predict(gram_valid)\n",
    "\n",
    "from collections import Counter\n",
    "Counter(pred_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 246, -1: 348})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_gamma=0.0001\n",
    "SVM_oneclass_kernelPrecomputed = svm.OneClassSVM(kernel='precomputed', gamma=value_gamma)\n",
    "# rbf kernel computation\n",
    "gram = np.exp(-value_gamma*cdist(data_train, data_train, 'euclidean')**2)\n",
    "SVM_oneclass_kernelPrecomputed.fit(gram) \n",
    "\n",
    "# predict on training examples\n",
    "gram_valid = np.exp(-value_gamma*cdist(data_valid, data_train, 'euclidean')**2)\n",
    "pred_anomaly = SVM_oneclass_kernelPrecomputed.predict(gram_valid)\n",
    "\n",
    "# from collections import Counter\n",
    "Counter(pred_anomaly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec un gamma à 0.001, on a : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_anomaly2 = pd.DataFrame(pred_anomaly)\n",
    "pred_anomaly2 = pred_anomaly2.replace(1, 0)\n",
    "pred_anomaly2 = pred_anomaly2.replace(-1, 1)\n",
    "\n",
    "data = {'seqID': np.arange(0,len(data_valid)), 'anomaly': pred_anomaly2[0]}\n",
    "y_test_template_gram = pd.DataFrame(data)\n",
    "y_test_template_gram[\"seqID\"] = y_test_template_gram[\"seqID\"].astype(int)\n",
    "y_test_template_gram[\"anomaly\"] = y_test_template_gram[\"anomaly\"].astype(int)\n",
    "\n",
    "y_test_template_gram.to_csv('y_test_template_gram.csv',  index = False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4e soumissions: \n",
    "    F1 Score: 0.67871 \n",
    "    Precision: 0.55021 \n",
    "    Recall: 0.88552\n",
    "On avait detecté 478 anomalies et 116 séquences normales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec un gamma à 0.0001, on a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_anomaly2 = pd.DataFrame(pred_anomaly)\n",
    "pred_anomaly2 = pred_anomaly2.replace(1, 0)\n",
    "pred_anomaly2 = pred_anomaly2.replace(-1, 1)\n",
    "\n",
    "data = {'seqID': np.arange(0,len(data_valid)), 'anomaly': pred_anomaly2[0]}\n",
    "y_test_template_gram = pd.DataFrame(data)\n",
    "y_test_template_gram[\"seqID\"] = y_test_template_gram[\"seqID\"].astype(int)\n",
    "y_test_template_gram[\"anomaly\"] = y_test_template_gram[\"anomaly\"].astype(int)\n",
    "\n",
    "y_test_template_gram.to_csv('y_test_template_gram0001.csv',  index = False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5e soumission:\n",
    "    F1 Score: 0.80000\n",
    "    Precision: 0.74138\n",
    "    Recall: 0.86869\n",
    "On avait detecté 348 anomalies et 246 séquences normales"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
